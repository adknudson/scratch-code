---
title: "Simulation Based Calibration"
author: "Alex Knudson"
date: "8/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

$$
\mu \sim \mathcal{N}(0, 1)
$$

$$
\sigma \sim \mathrm{lognormal}(0, 1)
$$

$$
y_n \sim \mathcal{N}(\mu, \sigma)
$$


```{stan output.var="m1"}
data {
  int<lower=1> J;
}
transformed data {
  real mu_ = normal_rng(0, 1);
  real<lower=0> sigma_ = lognormal_rng(0, 1);

  vector[J] y_sim;
  for (j in 1:J)
    y_sim[j] = normal_rng(mu_, sigma_);
}
parameters {
  real mu;
  real<lower=0> sigma;
}
model {
  mu ~ normal(0, 1);
  sigma ~ lognormal(0, 1);
  y_sim ~ normal(mu, sigma);
}
generated quantities {
  vector[J] y_ = y_sim;
  vector[2] pars_;
  int<lower=0, upper=1> ranks_[2] = {mu < mu_, sigma < sigma_};
  pars_[1] = mu_;
  pars_[2] = sigma_;
}
```


```{r}
output <- sbc(m1, data = list(J = 10), M = 1000)
```


```{r}
print(output)
```


```{r}
plot(output, bins = 30)
```


# Model 2

```{stan output.var="m2"}
data {
  int<lower=0> N; // Binomial size
  int<lower=0> J; // Number of rows
  int<lower=0> K; // Number of SOA values 
  vector[K] soa;  // SOA values
}
transformed data {
  real a_ = normal_rng(0, 0.1);
  real b_ = normal_rng(4, 2);

  int y_sim[J, K];
  vector[K] theta_ = inv_logit(exp(b_) * (soa - a_));
  for (j in 1:J) {
    for (k in 1:K) {
      y_sim[j, k] = binomial_rng(N, theta_[k]);
    }
  }
}
parameters {
  real a;
  real b;
}
model {
  vector[J] theta;

  a ~ normal(0, 0.1);
  b ~ normal(4, 2);

  theta = inv_logit(exp(b) * (soa - a));
  y_sim ~ binomial(N, theta);
}
generated quantities {
  int y_[J] = y_sim;
  vector[2] pars_;
  int<lower=0, upper=1> ranks_[2] = {a < a_, b < b_};
  pars_[1] = a_;
  pars_[2] = b_;
}
```

```{r}
K <- 45
soa <- seq(-0.5, 0.5, 0.05)
J <- length(soa)

out2 <- sbc(m2, 
            data = list(N = 5,
                        J = J,
                        K = K,
                        soa = soa), 
            M = 1000)
```


```{r}
print(out2)
plot(out2, bins = 30)
```

# Partisan Lean Model

```{r}
stanSBCcode <- "// This block reports to C++ the data types of all data that will be passed to
// Stan via the stan R function.
data {
	// These are integers that will be used to size the various vectors:
	// N_obs is the number of elections (observations)
	// N_sta is the number of states
	// K is the number of effects
	// np is the number of parameters. For sbc.
	int<lower=0> N_obs;
	int<lower=0> N_sta;
	int<lower=0> K;
	int<lower=0> np;

	// In order to use varying effects, we will need to identify the elections
	// by state. To do this, we will pass a vector to Stan containing an
	// identification number for each state. In practice, this will be the
	// factor of states from the rds file converted to a numeric vector.
	int states[N_obs];

	// The effects will be stored in a matrix x whose kth column corresponds
	// to the coefficient of the kth effect. E.g., for a linear model
	// alpha + beta * t, the first column will have 1 in each entry, and the
	// ith entry of the second column will have the value of t for the ith
	// observation.
	matrix[N_obs, K] x;

	// The observed values of partisan lean will be contained in the following
	// vector
	real Y_st[N_obs];

	// The following code contains values that we would like to play with.
	// To maintain the versatility of the Stan code, we will play with them
	// in R, opting to use Stan as a framework.
	real<lower = 0> betaSD;
}
// To perform sbc, we will need to simulate data from the model. Each
// parameter has a repeat here with an underscore after it. The underscore is
// to satisfy the convention requirements of the sbc function in R.
transformed data {
	//// Declare Variables ////
	// Standard deviation of partisan lean and vector containing the
	// nationwide baseline partisan lean
	real<lower=0> sigma_;
	vector[K] beta_;

	// The correlation matrix, vector of standard deviatons for effects, and
	// vector of vectors for varying effects
	corr_matrix[K] Omega_;
	vector<lower=0>[K] sigma_k_;
	vector[K] x_s_[N_sta];

	// The vector of means based on pulled effects and the resulting vector
	// of simulated partisan lean data
	vector[N_obs] mu_;
	vector[N_obs] Y_st_sim;

	//// Simulate the data ////
	// First, randomly simulate sigma and the nationwide effects.
	sigma_ = exponential_rng(1);
	for (i in 1:K)
		beta_[i] = normal_rng(0,1);

	// Next, randomly simulate standard deviations for the effects, and use
	// those standard deviations to randomly simulate effects.
	Omega_ = lkj_corr_rng(2, 1);
	for (i in 1:K)
		sigma_k_[i] = exponential_rng(1);
	for (j in 1:N_sta)
		x_s_[j] = multi_normal_rng(beta_, quad_form_diag(Omega_, sigma_k_));

	// Last, use the results to create the vector of means and use those to
	// simulate the partisan lean data.
	for (i in 1:N_obs)
		mu_[i] = x[i] * x_s_[states[i]];
	for (i in 1:N_obs)
		Y_st_sim[i] = normal_rng(mu_[i], sigma_);
}
parameters {
	// First, we have sigma, the fixed variance of the partisan lean. After
	// that, we have the vector of nationwide averages of the features of the
	// model.
	real<lower=0> sigma;
	vector[K] beta;

	// Next, we have the parameters that will be used to generate the features
	// varying by state.
	// Omega is a correlation matrix
	// sigma_k is the vector of standard deviations for each of the features
	// x_s will contain the features
	corr_matrix[K] Omega;
	vector<lower=0>[K] sigma_k;
	vector[K] x_s[N_sta];
}
model {
	// In C++, data type declarations must precede the rest of the code.
	// mu will be used to contain the measurements of mean in each state
	vector[N_obs] mu;

	// We assign distributions to the nationwide parameters. Note that
	// assigning distribution to beta itself automatically assigns it to each
	// entry of the variable.
	sigma ~ exponential(1);
	beta ~ normal(0, betaSD);

	// The following lines handle the varying effects. We use the LJKcorr
	// distribution to uniformly sample the space of correlation matrices
	// between the features. Then the features are pulled randomly as a
	// multivariable normal vector.
	Omega ~ lkj_corr(2);
	sigma_k ~ exponential(1);
	x_s ~ multi_normal(beta, quad_form_diag(Omega, sigma_k));

	// Here, we multiply the coefficients of the features with their
	// corresponding features. Note that Stan (or C++) is handling a dot
	// product here.
	for (i in 1:N_obs)
		mu[i] = x[i] * x_s[states[i]];

	// Finally, we wrap it all up by setting the model as follows.
	// Y_st ~ normal(mu, sigma);

	Y_st_sim ~ normal(mu, sigma);
}
generated quantities {
	vector[np] pars_;
	int ranks_[np];

	ranks_[1] = sigma > sigma_;
	for (i in 1:K)
		ranks_[i + 1] = beta[i] > beta_[i];

	pars_[1] = sigma_;
	for (i in 1:K)
		pars_[i + 1] = beta_[i];
}"
```


```{r}
# Read data and filter out unavailable data
dat <- readRDS("~/Downloads/By_Year_State_updated_2.rds")
dat <- dat %>% filter(!is.na(Y_st))

K <- 2
# Form data list for the stan model
stanDat <- list(
  N_obs = length(dat$Y_st), 			    # Num observations
	N_sta = length(unique(dat$States)), # Num states
	K = 2, 							 	              # Num effects
	states = as.numeric(dat$States),    # Factor of states as integer vec
	x = matrix(c(rep(1,length(dat$t)), dat$t), ncol = 2), # Obs matrix
	Y_st = dat$Y_st,                    # Partisan Lean
	betaSD = 1,                         # Standard devation of beta.
	np = 1 + K                          # Number of parameters. Needed for sbc
)
```

```{r}
stanFitModel <- stan_model(model_code = stanSBCcode)
stanSBC <- sbc(stanFitModel, data = stanDat, M = 100)
```


```{r}
print(stanSBC)
plot(stanSBC, bins = 30)
```
